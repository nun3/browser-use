"""
Agente Browser Use com suporte completo para OpenAI GPT
Vers√£o especializada para usar exclusivamente o OpenAI GPT
"""

import os
from dotenv import load_dotenv
import asyncio
import datetime
import base64
from pathlib import Path

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()
load_dotenv('config.env')

def salvar_evidencia(evidencias_dir, conteudo, nome_arquivo):
    """
    Salva evid√™ncias em arquivo txt
    """
    arquivo_evidencia = Path(evidencias_dir) / f"{nome_arquivo}.txt"
    with open(arquivo_evidencia, 'w', encoding='utf-8') as f:
        f.write(conteudo)
    print(f"Evid√™ncia salva: {arquivo_evidencia}")

def salvar_screenshot(evidencias_dir, screenshot_data, nome_arquivo):
    """
    Salva screenshot em arquivo PNG
    """
    if screenshot_data:
        # Remove o prefixo data:image/png;base64, se existir
        if ',' in screenshot_data:
            screenshot_data = screenshot_data.split(',')[1]
        
        # Decodifica base64 e salva
        screenshot_bytes = base64.b64decode(screenshot_data)
        arquivo_screenshot = Path(evidencias_dir) / f"{nome_arquivo}.png"
        with open(arquivo_screenshot, 'wb') as f:
            f.write(screenshot_bytes)
        print(f"Screenshot salvo: {arquivo_screenshot}")

def configurar_gpt():
    """
    Configura o OpenAI GPT exclusivamente
    """
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key or api_key == 'your_openai_api_key_here':
        print("‚ùå OPENAI_API_KEY n√£o configurada no config.env")
        print("üìù Configure sua chave da OpenAI em: https://platform.openai.com/api-keys")
        return None
    
    try:
        from browser_use import ChatOpenAI
        print("ü§ñ Configurando OpenAI GPT...")
        print(f"üîë Chave encontrada: {api_key[:10]}...")
        
        modelo = os.getenv('OPENAI_MODEL', 'gpt-4o')
        llm = ChatOpenAI(
            model=modelo,
            api_key=api_key,
            temperature=0.7
        )
        print(f"‚úÖ OpenAI GPT configurado com sucesso! Modelo: {modelo}")
        return llm
        
    except ImportError:
        print("‚ùå Erro: ChatOpenAI n√£o dispon√≠vel")
        print("üì¶ Instale com: pip install openai")
        return None
    except Exception as e:
        print(f"‚ùå Erro ao configurar OpenAI GPT: {e}")
        return None

async def main():
    """
    Fun√ß√£o principal que executa o agente com OpenAI GPT
    """
    print("üöÄ Iniciando agente Browser Use com OpenAI GPT...")
    
    # Configura o OpenAI GPT
    llm = configurar_gpt()
    if not llm:
        print("‚ùå N√£o foi poss√≠vel configurar o OpenAI GPT")
        return
    
    from browser_use import Agent
    
    # Define a tarefa que o agente deve executar
    task = ("Analise completamente a aplica√ß√£o Bibliotech em https://bibliotechapp.vercel.app/login "
            "Realize login com email: thegoldengrace@gmail.com e senha: 123456 "
            "Explore todas as funcionalidades dispon√≠veis: navega√ß√£o, empr√©stimos, devolu√ß√µes, reservas, perfil do usu√°rio, etc. "
            "Teste diferentes cen√°rios: buscar livros, filtrar, ordenar, paginar, etc. "
            "Identifique todas as funcionalidades e fluxos da aplica√ß√£o "
            "Gere cen√°rios de teste em formato Gherkin (Given-When-Then) para cada funcionalidade descoberta "
            "Inclua cen√°rios positivos e negativos para cada feature "
            "Organize os cen√°rios por funcionalidade (Login, Busca de Livros, Empr√©stimo, Devolu√ß√£o, Reserva, Perfil, etc.) "
            "Seja detalhado e cubra todos os casos de uso poss√≠veis ")
    
    # Prompt para gera√ß√£o de relat√≥rio detalhado
    prompt_relatorio = f"""
            Com base na explora√ß√£o aut√¥noma realizada no Bibliotech em {datetime.datetime.now().strftime('%d/%m/%Y %H:%M:%S')}:
            
            Gere um relat√≥rio detalhado incluindo:
            1. **RESUMO DOS TESTES EXECUTADOS:** Lista de a√ß√µes realizadas com status (sucesso/falha).
            2. **FUNCIONALIDADES DESCOBERTAS:** Descri√ß√£o detalhada de todas as funcionalidades encontradas.
            3. **FLUXOS IDENTIFICADOS:** Mapeamento dos principais fluxos de usu√°rio.
            4. **PROBLEMAS IDENTIFICADOS:** Bugs ou falhas encontradas.
            5. **AN√ÅLISE DE USABILIDADE:** Facilidade de navega√ß√£o e clareza.
            6. **AN√ÅLISE DE SEGURAN√áA:** Funcionamento de login/logout e prote√ß√µes.
            7. **CEN√ÅRIOS GHERKIN COMPLETOS:** Gere cen√°rios detalhados em formato Gherkin para TODAS as funcionalidades descobertas, incluindo:
               - Cen√°rios positivos (happy path)
               - Cen√°rios negativos (edge cases)
               - Cen√°rios de erro
               - Cen√°rios de valida√ß√£o
               - Organize por funcionalidade (Login, Busca, Empr√©stimo, Devolu√ß√£o, Reserva, Perfil, etc.)
            8. **COBERTURA DE TESTES:** Mapeamento de quais funcionalidades precisam de mais testes.
            9. **RECOMENDA√á√ïES:** Melhorias sugeridas baseadas na an√°lise.
            10. **SCORE GERAL:** Avalia√ß√£o de 1-10 por aspecto e geral.
            """
    
    # Criar pasta de evid√™ncias com timestamp
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    evidencias_dir = f"evidencias/teste_gpt_{timestamp}"
    os.makedirs(evidencias_dir, exist_ok=True)
    
    print(f"üìÅ Evid√™ncias ser√£o salvas em: {evidencias_dir}")
    print(f"üéØ Tarefa: {task[:100]}...")
    
    # Cria o agente com a tarefa e o LLM
    agent = Agent(task=task, llm=llm)
    
    # Executa o agente e captura o resultado
    resultado = await agent.run()
    
    # Gera relat√≥rio detalhado usando o LLM
    print("\nGerando relat√≥rio detalhado...")
    relatorio_prompt = f"""
{prompt_relatorio}

DADOS DA EXECU√á√ÉO:
- Tarefa: {task}
- Resultado: {resultado}
- Data/Hora: {datetime.datetime.now().strftime('%d/%m/%Y %H:%M:%S')}

Por favor, gere um relat√≥rio completo baseado nos dados acima.
"""
    
    # Gera o relat√≥rio usando o LLM
    try:
        relatorio_resposta = await llm.ainvoke(relatorio_prompt)
        relatorio_detalhado = relatorio_resposta.content
    except Exception as e:
        relatorio_detalhado = f"Erro ao gerar relat√≥rio: {str(e)}"
    
    # Salva evid√™ncias do teste
    evidencia_conteudo = f"""
TESTE AUTOMATIZADO - BIBLIOTECH COM OPENAI GPT
Data/Hora: {datetime.datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
Timestamp: {timestamp}

TAREFA EXECUTADA:
{task}

RESULTADO DA EXECU√á√ÉO:
{resultado}

RELAT√ìRIO DETALHADO:
{relatorio_detalhado}

PROMPT DE RELAT√ìRIO ORIGINAL:
{prompt_relatorio}
"""
    
    # Salva as evid√™ncias em arquivo txt
    salvar_evidencia(evidencias_dir, evidencia_conteudo, f"evidencias_teste_gpt_{timestamp}")
    
    # Salva tamb√©m apenas o relat√≥rio detalhado
    salvar_evidencia(evidencias_dir, relatorio_detalhado, f"relatorio_detalhado_gpt_{timestamp}")
    
    print(f"\nTeste conclu√≠do! Evid√™ncias salvas em: {evidencias_dir}")
    print("Arquivos gerados:")
    print(f"- evidencias_teste_gpt_{timestamp}.txt")
    print(f"- relatorio_detalhado_gpt_{timestamp}.txt")
    print(f"- Screenshots (se capturados)")

if __name__ == "__main__":
    # Executa a fun√ß√£o principal de forma ass√≠ncrona
    asyncio.run(main())
